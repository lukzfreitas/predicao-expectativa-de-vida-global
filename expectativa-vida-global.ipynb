{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9pETg6BD7EX"
   },
   "source": [
    "<h1 align=\"center\"> Trabalho II - Inteligência de Negócios </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> Integrantes: Camila Moser, Júlia Dorneles, Lucas Freitas e Tamires Domingues </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Descrição Geral do Trabalho </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    A base de dados coletado sobre expectativa de vida, possui fatores relacionados a saúde, disponibilizados pela <i>Global Health Observatotory</i> (GHO), sob a Organização Mundial de Saúde (OMS). Foi considerado dados registrados em 15 anos (2000 a 2015) para 193 países, os dados consideram fatores relacionados a imunização, mortalidade, econômicos e sociais. O conjunto de dados possui 2938 registros e 22 atributos. Optamos por escolher esta base de dados por considerar de grande importância descobrir as relações entre fatores sociais, econômicos e saúde, com a expectativa de vida em diferentes lugares no mundo, além de poder prever a expectativa de vida baseada nesses fatores.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importação das bibliotecas em python </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TZIp597o9jJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGgvDR4-YZeg"
   },
   "source": [
    "<h3>Descrição geral das variáveis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variável | Descrição |\n",
    "| --- | --- |\n",
    "| País | 193 - Países |\n",
    "| Continentes | América do Sul, América do Norte, Europa, África, Ásia, Oceania |\n",
    "| Ano | Anos 2000 - 2015 |\n",
    "| Status | Desenvolvido e em desenvolvimento |\n",
    "| Expectativa de vida | Expectativa de vida em idade, será transformado em categórico (Classificação) |\n",
    "| Mortalidade Adulta | Taxa de mortalidade de adultos de ambos os sexos (probabilidade de morrer entre 15 e 60 anos por 1000 habitantes) |\n",
    "| Mortes infantis | Número de Mortes Infantis por 1000 habitantes |\n",
    "| Álcool | Álcool, consumo per capita (15+) registrado (em litros de álcool puro) Porcentagem de gasto |\n",
    "| Porcentagem de gasto | Despesas com saúde em percentagem do Produto Interno Bruto per capita (%) |\n",
    "| Hepatite B | Cobertura vacinal contra hepatite B (HepB) em crianças de 1 ano (%) |\n",
    "| Sarampo | Sarampo - número de casos notificados por mil habitantes |\n",
    "| BMI | Índice de massa corporal médio da população total |\n",
    "| Mortes abaixo dos cinco anos | Número de mortes abaixo de cinco por mil habitantes |\n",
    "| Poliomielite | Cobertura de imunização contra a poliomielite (Pol3) em crianças de 1 ano (%) |\n",
    "| Despesa total | Despesa das administrações públicas em saúde como percentagem da despesa total do governo (%) de 1 ano (%) |\n",
    "| Difteria | Cobertura de imunização contra toxóide tetânico da difteria e coqueluche (DTP3) em crianças de 1 ano de idade (%) |\n",
    "| HIV/AIDS  | Mortes por 1.000 nascidos vivos VIH / SIDA (0-4 anos) |\n",
    "| GDP | Produto Interno Bruto per capita (em USD) |\n",
    "| População | População de um país |\n",
    "| Magreza entre adolescentes entre 10 e 19 anos | Prevalência de magreza entre crianças e adolescentes entre 10 e 19 anos (%) |\n",
    "| Magreza entre crianças entre 5 e 9 anos | Prevalência de magreza entre crianças de 5 a 9 anos (%) |\n",
    "| Composição de renda dos recursos | Índice de Desenvolvimento Humano em termos de composição de renda dos recursos (índice variando de 0 a 1) |\n",
    "| Escolaridade | Número de anos de escolaridade (anos) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A base de dados foi coletada no site <a href=\"https://www.kaggle.com\"> Kaggle</a>, disponível neste <a href=\"https://www.kaggle.com/kumarajarshi/life-expectancy-who\"> link</a> em formato csv </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2povwnbo9jP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Life-Expectancy-Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Na tabela gerada abaixo é possível visualizar os 5 primeiros registros do arquivo csv </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Esta base dados possui 2938 registros (linhas) e 23 atributos (colunas) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Nesta base de dados é possível visualizar a informação da quantidade total de registros preenchidos em cada atributo e seu tipo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1553514742178,
     "user": {
      "displayName": "Rodrigo Espindola",
      "photoUrl": "",
      "userId": "00623881267366709334"
     },
     "user_tz": 180
    },
    "id": "kTESur0OBzxm",
    "outputId": "ec510605-8dad-4715-b8e7-533c8d76264c"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p> Abaixo é possível visualizar a soma total de cada atributo onde seu registro não foi preenchido. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Análise e pré-processamento dos dados </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Após descobrirmos qual tipo cada atributo pertence (numérico ou categórico), e se há valores ausentes. Começamos a utilizar as técnicas de pré-processamento para normalizar os dados. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Para a coluna alvo 'expectativa de vida' em que seus valores estiverem ausentes, optamos por remover toda linha deste registro. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.isfinite(df['expectativa_vida'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Os atributos numéricos que seu valor estiver ausente, optamos por preencher com a média total dos valores deste atributo que foram preenchidos. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcool_mean = df['alcool'].mean()\n",
    "hepatiteB_mean = df['hepatiteB'].mean()\n",
    "BMI_mean = df['BMI'].mean()\n",
    "poliomielite_mean = df['poliomielite'].mean()\n",
    "despesa_total_mean = df['despesa_total'].mean()\n",
    "difteria_mean = df['difteria'].mean()\n",
    "GDP_mean = df['GDP'].mean()\n",
    "populacao_mean = df['populacao'].mean()\n",
    "magreza_10_19_idade_mean = df['magreza_10_19_idade'].mean()\n",
    "magreza_5_9_idade_mean = df['magreza_5_9_idade'].mean()\n",
    "composicao_renda_recurso_mean = df['composicao_renda_recurso'].mean()\n",
    "escolaridade_mean = df['escolaridade'].mean()\n",
    "\n",
    "df['alcool'].fillna(alcool_mean, inplace=True)\n",
    "df['hepatiteB'].fillna(hepatiteB_mean, inplace=True)\n",
    "df['BMI'].fillna(BMI_mean, inplace=True)\n",
    "df['poliomielite'].fillna(poliomielite_mean, inplace=True)\n",
    "df['despesa_total'].fillna(despesa_total_mean, inplace=True)\n",
    "df['difteria'].fillna(difteria_mean, inplace=True)\n",
    "df['GDP'].fillna(GDP_mean, inplace=True)\n",
    "df['populacao'].fillna(populacao_mean, inplace=True)\n",
    "df['magreza_10_19_idade'].fillna(magreza_10_19_idade_mean, inplace=True)\n",
    "df['magreza_5_9_idade'].fillna(magreza_5_9_idade_mean, inplace=True)\n",
    "df['composicao_renda_recurso'].fillna(composicao_renda_recurso_mean, inplace=True)\n",
    "df['escolaridade'].fillna(escolaridade_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Decidimos por criar o atributo \"continente\" baseada nas informações do atributo \"país\" após isso decidimos remover o atributo \"país\" e utilizar o atributo \"continente\". Caso aplicássemos a técnica de normalização \"one hot encoding\" nos valores do atributo \"país\", teriámos que criar a mais 193 atributos (193 países), isso iria ocasionar o problema de alta dimensionalidade (aumento da complexidade do processamento) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='pais', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Decidimos também por remover o atributo 'mortes_abaixo_5_anos, pois possui ambiguidade com o atributo 'mortes_infantis' </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='mortes_abaixo_5_anos', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Separamos todos nosso conjunto de dados em <font color=\"blue\">categóricos</font>, <font color=\"blue\">numéricos</font> e <font color=\"blue\">alvo</font> para realizar a análise e a preparação dos dados para cada tipo de atributo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricos = ['continente', 'status']\n",
    "numericos = [  \n",
    "    'ano',\n",
    "    'mortalidade_adulta',\n",
    "    'mortes_infantis',\n",
    "    'alcool',\n",
    "    'porcentagem_gasto',\n",
    "    'hepatiteB',\n",
    "    'sarampo',\n",
    "    'BMI',    \n",
    "    'poliomielite',\n",
    "    'despesa_total',\n",
    "    'difteria',\n",
    "    'hiv/aids',\n",
    "    'GDP',\n",
    "    'populacao',\n",
    "    'magreza_10_19_idade',\n",
    "    'magreza_5_9_idade',\n",
    "    'composicao_renda_recurso',\n",
    "    'escolaridade'\n",
    "]\n",
    "alvo = 'expectativa_vida'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Dados do tipo numéricos </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[numericos]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Dados do tipo categórico </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categoricos].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Análise e Descoberta de Conhecimento </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Nesta etapa é realizada a análise dos valores do nosso conjunto de dados, a partir desta análise é possível descobrir correlação entre valores dos diferentes atributos através de percentuais, indíces e gráficos. </p>\n",
    "<p> Na tabela abaixo é possivel visualizar uma representação da nossa base de dados com informações relevantes para\n",
    " análise dos atributos. Entre as informações contidas nessa representação estão a média dos valores, o desvio padrão,\n",
    "o valor mínimo e máximo e percentual </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A partir desta análise observamos que a idade mínima e máxima registrada na coluna \"expectativa_vida\" da nossa base de dados é de 36,3 e 89 anos de idade respectivamente e a média de idade 69 anos. Estas descobertas foram importantes pois elas influenciaram na decisão da discretização dos valores da coluna \"expectativa_vida\" em intervalos categorizados em <font color=\"blue\">muito baixa</font>, <font color=\"blue\">baixa</font>, <font color=\"blue\">média</font> e <font color=\"blue\">alta</font> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1553514767714,
     "user": {
      "displayName": "Rodrigo Espindola",
      "photoUrl": "",
      "userId": "00623881267366709334"
     },
     "user_tz": 180
    },
    "id": "iSrO2OLaB6uf",
    "outputId": "7178ce76-f96e-4226-d3be-c073fd3551cd"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Correlação (de Pearson) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A correlação indica a força e a direção de um relacionamento linear entre 2 variáveis, ela varia entre [-1, 1] onde as extremidades indicam um relacionamento linear perfeito, onde 1 (positivo perfeito) e -1 (negativo perfeito) e 0 significa que não existe relacionamento linear entre duas variáveis </p>\n",
    "<p> A seguir é apresentado uma matriz de correlação com os atributos e seus relacionamentos, cada relacionamento é representado por uma escala de cor verde, onde quanto mais escuro maior é a correlação entre dois atributos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df[numericos + [alvo]].corr()\n",
    "cm = sn.light_palette(\"green\", as_cmap=True)\n",
    "\n",
    "s = corr.style.background_gradient(cmap=cm)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Ao analisar a matriz de correlação, foi possível descobrir conhecimentos intríseco nos dados, como por exemplo: quanto maior a escolaridade, maior a expectativa de vida (correlaçao linear positiva).</p>\n",
    "<p> Além desta descoberta, também conseguimos notar que quanto maior O IDH (Índice de Desenvolvimento Humano) maior a expectativa de vida e maior a escolaridade. Também foi possível validar algumas correlações evidentes como a relação entre mortalidade adulta com a expectativa de vida.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Abaixo é apresentado os gráficos de correlação linear das análises descritas anteriomente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['escolaridade'],df['expectativa_vida'])\n",
    "plt.title(\"Expectativa de vida vs Escolaridade\")\n",
    "plt.xlabel('Escolaridade')\n",
    "plt.ylabel('Expectativa de vida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['composicao_renda_recurso'],df['expectativa_vida'])\n",
    "plt.title(\"Expectativa de vida vs IDH\")\n",
    "plt.xlabel('IDH')\n",
    "plt.ylabel('Expectativa de vida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['mortalidade_adulta'],df['expectativa_vida'])\n",
    "plt.title(\"Expectativa de vida vs Mortalidade adulta\")\n",
    "plt.xlabel('Mortalidade adulta')\n",
    "plt.ylabel('Expectativa de vida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> IDH vs Escolaridade </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['composicao_renda_recurso'],df['escolaridade'])\n",
    "plt.title(\"IDH vs Escolaridade\")\n",
    "plt.xlabel('IDH')\n",
    "plt.ylabel('Escolaridade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Discretização do atributo classe \"expectativa de vida\" </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Como neste trabalho iremos utilizar algoritmos de classificação para prever a coluna \"expectativa_vida\", se fez  necessário transformar os valores deste atributo numérico na forma de atributos categóricos.\n",
    "A transformação deste atributo numérico em categórico envolveu duas subtarefas:\n",
    "<p> Decidir quantas categorias este atributo irá ter, neste passo, após os valores numéricos deste atributo estarem ordenados eles são divididos em <i>n</i> intervalos especificando-se <i>n</i> pontos de divisão, no segundo e trivial  passo, todos os valores de um intervalo são mapeados para o mesmo valor de categoria. Utilizamos 4 categorias divididas em <font color=\"blue\">muito baixa</font> menor ou igual a 50 anos, <font color=\"blue\">baixa</font> maior que 50 e menor ou igual a 60 anos, <font color=\"blue\">média</font> maior que 60 e menor ou igual a 75 anos e <font color=\"blue\">alta</font> maior que 75 anos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = (0, 50, 60, 75, 100)\n",
    "category_expectiva_vida = ['muito baixa', 'baixa', 'média', 'alta']\n",
    "df['expectativa_vida'] = pd.cut(df['expectativa_vida'], bins = bins, labels = category_expectiva_vida)\n",
    "df['expectativa_vida'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Distribuição da Expectativa de Vida Global </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> O gráfico a seguir apresenta a distribuição total e a porcentagem dos registros em cada categoria, a partir desta análise podemos observar que a expectivativa de vida categorizada como <font color=\"blue\">média</font> possui metade do predomínio do conjunto de dados, e a categoria <font color=\"blue\">muito baixa</font> possui o menor número de registros. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muito_baixa = (df['expectativa_vida'] == 'muito baixa').sum()\n",
    "baixa = (df['expectativa_vida'] == 'baixa').sum()\n",
    "media = (df['expectativa_vida'] == 'média').sum()\n",
    "alta = (df['expectativa_vida'] == 'alta').sum()\n",
    "\n",
    "total = muito_baixa + baixa + media + alta\n",
    "percent_muito_baixa = muito_baixa/total\n",
    "percent_baixa = baixa/total\n",
    "percent_media =  media/total\n",
    "percent_alta =  alta/total\n",
    "\n",
    "print('Muito Baixa =', muito_baixa)\n",
    "print('Baixa =', baixa)\n",
    "print('Média =', media)\n",
    "print('Alta =', alta)\n",
    "print('Percentual Muito Baixa: ', percent_muito_baixa * 100, '%')\n",
    "print('Percentual Baixa: ', percent_baixa * 100, '%')\n",
    "print('Percentual Média: ', percent_media * 100, '%')\n",
    "print('Percentual Alta: ', percent_alta * 100, '%')\n",
    "\n",
    "objects = ('muito baixa', 'baixa', 'média', 'alta')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [muito_baixa, baixa, media, alta]\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Total de registros')\n",
    "plt.title('Distribuição total dos registros em categorias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Distribuição da expectativa de vida por continentes </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> No gráfico a seguir é possível analisar com maior detalhamento a distribuição dos registros em gráficos de barras com valores de 0 a 100, onde cada barra representa um continente, cada barra é dividida em cores que representam as categorias do atributo alvo expectativa de vida. Neste gráfico é possível observar que a expectativa de vida <font color=\"blue\">média</font> é predominante nos continentes: América do Norte, América do Sul, Oceania e Ásia.</p>\n",
    "<p> Os continentes Europa e África foram os únicos que não tiveram expectativa de vida média como predominantes, a Europa teve maior número de registros classificados como Alta, a Áfria teve mais registros classificados como baixa, sendo o único continente com registros classificados como muito baixa. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chart = df.pivot_table(values=['status'], index=['continente'], columns=['expectativa_vida'], aggfunc='count')\n",
    "x_chart = x_chart.apply(lambda c: c / c.sum() * 100, axis=1)\n",
    "x_chart.plot(kind=\"bar\",stacked=True)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Transformação dos Dados </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A etapa de preparação dos dados tem por objetivo converter os valores dos atributos categóricos em valores numéricos, normalizá-los e re-escalar. Esta etapa é necessária para os algoritmos de classificação que trabalham apenas com variáveis númericas. A conversão dos atributos nominais podem ser feitas por meio de <b>binarização</b> e <b>codificação 1-de-n<b> <i>(one-hot-enconding)</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mortes_infantis'] = df['mortes_infantis'].astype(float)\n",
    "df['sarampo'] = df['sarampo'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Re-escalar valores dos atributos numéricos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalização do atributo 'continente' utilizando a codificação 1-de-n (<i>one-hot encoding</i>) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_continente = LabelBinarizer()\n",
    "continente = lb_continente.fit_transform(df['continente'].values)\n",
    "print(\"Classes aprendidas: \",lb_continente.classes_)\n",
    "print(\"Dados: \", continente)\n",
    "X = np.c_[X, continente ]\n",
    "X\n",
    "numericos = np.append(numericos,lb_continente.classes_)\n",
    "numericos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalização do atributo 'status' utilizando a codificação 1-de-n (<i>one-hot encoding</i>) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_status = LabelBinarizer()\n",
    "status = lb_status.fit_transform(df['status'].values)\n",
    "print(\"Classes aprendidas: \",lb_status.classes_)\n",
    "print(\"Dados: \", status)\n",
    "X = np.c_[X, status ]\n",
    "X\n",
    "numericos = np.append(numericos,lb_status.classes_)\n",
    "numericos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> O número de colunas após a normalização dos dados utilizando <i>one-hot enconding</i> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Avaliação de Desempenho dos Classificadores </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Calcular o desempenho preditivo em termos de taxa de acerto ou de erro utilizando a mesma base de dados acaba ocasionando modelos viciados chamados de <i>overfitting</i>, devem-se então utilizar métodos de amostragem alternativos para obter estimativas de desempenho preditivo mais confiáveis, definindo conjuntos de treino e teste. Os dados de treinamento são empregados na indução e no ajuste do modelo, enquanto os exemplos de testes simulam a apresentação de objetos novos ao preditor, os quais não foram vistos antes em sua indução.</p>\n",
    "<p> Dois dos principais métodos de amostragem existentes foram utilizados neste trabalho, <i>Holdout</i> e Validação Cruzada (<i>cross validation</i>) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Atribuir a variável 'y' a classe alvo 'expectativa_vida' </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['expectativa_vida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Método Hold Out </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Neste método, os dados são divididos em dois conjuntos disjuntos, chamados de treinamento e teste, um modelo de classificação é então induzido a partir do conjunto de treinamento e seu desempenho é avaliada no conjunto de teste. A proporção dos dados reservados para treinamento geralmente fica em 2/3 e para teste 1/3. O modelo <i>holdout</i> possui diversas limitações pois devido aos conjuntos de treinamento e teste serem suconjuntos de dados originais, uma classe que esteja representada em excesso em um subconjunto estará representada de menos na outra e vice-versa.</p>\n",
    "<p> A solução que utilizamos poderá mitigar este problema é crar sbuconjuntos de treinamento e teste de registros aleatoriamente (random_state=42) como o exemplo a seguir. Separando o treinamento (X_train) em 70% (2049 registros), e 30% para o subconjunto teste (X_test) (879 registros) a separação dos registros.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Método Validação Cruzada (<i>Cross Validation</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Outra alteranativa é o uso do método validação cruzada, neste trabalho utilizaremos <i>k</i> partições de tamanhos iguais, durante cada execução, uma das partições é escolhida para teste, enquanto outras são usadas para treinamento, este procedimento é repetido <i>k</i> vezes de modo que cada partição seja utilizada para teste exatamente uma vez. A desvantagem desta abordagem que computacionalmente é custuso repetir <i>k</i> vezes este procedimento.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Modelos Preditivos (Classificação) </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> K-Nearest Neighbours </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Este algoritmo é o mais simples entre todos os algoritmos de aprendizagem de máquina, possui como parâmetro de entrada o número de vizinhos mais próximos <i>k</i>, definida pelo usuário. Este parâmetro influencia diretamente na taxa de acerto do algoritmo, por exemplo, quando inserimos um valor de <i>k</i> baixo, ele é mais propício a errar a classificação por causa de <i>outliers</i>. Este algoritmo utiliza o método baseado na distância entre dois pontos, geralmente usado pelo cálculo da distância Euclidiana, onde, quanto menor a distância entre dois pontos maior a chance deste ponto fazer parte desta classe.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Para analisarmos qual melhor valor de <i>k</i> para o algoritmo, fizemos um teste com valores de k entre 1 a 19, apenas com valores ímpares para evitar empates, criamos o modelo preditivo para cada <i>k</i> e aplicamos o conjunto de teste ao modelo, com isso obtemos o resultado da acurácia para cada modelo e aplicamos em um gráfico para analisarmos melhor.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "lista_n = [1,3,5,7,9,11,13,15,17,19]\n",
    "for n in lista_n:\n",
    "    modelo_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    modelo_knn.fit(X_train,y_train)\n",
    "    pred_knn = modelo_knn.predict(X_test)    \n",
    "    accuracy = accuracy_score(y_test,pred_knn)\n",
    "    results.append(accuracy)    \n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "pd.Series(results, lista_n).plot(color=\"darkred\",marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Ao Analisarmos o gráfico notamos que <i>k</i> igual a 3 obteve melhor acurácia </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Criando Modelo K-NN </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "modelo_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Aplicando Modelo de Aprendizagem ao conjunto de teste </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = modelo_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Medidas de Desempenho </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('matrix de confusão')\n",
    "print(confusion_matrix(y_test, pred_knn))\n",
    "print(classification_report(y_test, pred_knn))\n",
    "print('Acurácia', accuracy_score(y_test,pred_knn))\n",
    "print('Taxa de erro', np.mean(pred_knn != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Validation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Analisamos através de um gráfico qual o melhor valor de <i>k</i> (vizinhos próximos) com melhor acurácia </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "lista_n = [1,3,5,7,9,11,13,15,17,19]\n",
    "for n in lista_n:    \n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "    results.append(scores.mean())        \n",
    "plt.figure(figsize=(8,4))\n",
    "pd.Series(results, lista_n).plot(color=\"darkred\",marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Melhor <i>k</i> encontrado foi igual a 1</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Accuracy: %0.2f Desvio Padrão: (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Decision Tree </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O algoritmo <i>Decision Tree</i> ou Árvore de Decisão. Ele utiliza a estratégia de dividir para conquistar para resolver um problema de decisão, este algoritmo geralmente empregam uma estratégia que cresce uma árvore de decisão tomando uma série de decisões localmente ótimas sobre qual atributo usar para particionar os dados. Um desses algoritmos é o algoritmo de <i>Hunt</i>. Em uma árvore de decisão, cada nodo folha recebe um rótulo de classe, os nodos internos e o nodo raiz, contém condições de testes de atributos para separar registros que possuem características diferentes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Para analisarmos qual melhor valor para o parâmetro de entrada relacionada a profundidade máxima da árvore, fizemos um teste com valores entre 2 a 20, apenas com valores pares, criamos o modelo preditivo para cada profundidade máxima e aplicamos o conjunto de teste ao modelo, com isso obtemos o resultado da acurácia para cada modelo e aplicamos em um gráfico para analisarmos melhor.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "max_depth_options = [2,4,6,8,10,12,14,16,18,20]\n",
    "for trees in max_depth_options:\n",
    "    modelo_dtree = DecisionTreeClassifier(max_depth=trees, random_state=101, max_features = None, min_samples_leaf = 4)\n",
    "    modelo_dtree.fit(X_train, y_train)\n",
    "    pred_tree = modelo_dtree.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,pred_tree)\n",
    "    results.append(accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "pd.Series(results, max_depth_options).plot(color=\"darkred\",marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gerando gráfico com o modelo da árvore de decisão </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['mortalidade_adulta', 'mortes_infantis', 'alcool',\n",
    "       'porcentagem_gasto', 'hepatiteB', 'sarampo', 'BMI',\n",
    "       'poliomielite', 'despesa_total', 'difteria', 'hiv/aids', \n",
    "       'GDP', 'populacao', 'magreza_10_19_idade', 'magreza_5_9_idade',\n",
    "       'composicao_renda_recurso', 'escolaridade',       \n",
    "       'América do Norte', 'América do Sul', 'Europa', 'Oceania',\n",
    "       'África', 'Ásia', 'Desenvolvido', 'Em Desenvolvimento'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['muito baixa', 'baixa', 'média', 'alta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo_dtree = DecisionTreeClassifier(max_depth=8, random_state=101, max_features = None, min_samples_leaf = 4)\n",
    "modelo_dtree = modelo_dtree.fit(X_train, y_train)\n",
    "dot_data = tree.export_graphviz(modelo_dtree, out_file=None, \n",
    "                     feature_names=feature_names,  \n",
    "                     class_names=target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "# Salvo um arquivo no formato pdf \n",
    "graph.render(\"modelo_arvore_decisao\") \n",
    "# Exibe o gráfico da árvore gerada\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Aplicando modelo de aprendizagem ao conjunto de teste </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dtree = modelo_dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Medidas de Desempenho </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('matrix de confusão')\n",
    "print(confusion_matrix(y_test, pred_dtree))\n",
    "print(classification_report(y_test, pred_dtree))\n",
    "print('Acurácia', accuracy_score(y_test,pred_dtree))\n",
    "print('Taxa de erro', np.mean(pred_dtree != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Validation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Analisamos através de um gráfico qual o melhor valor da profundida máxima da árvore de decisão para obter uma melhor acurácia </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "max_depth_options = [2,4,6,8,10,12,14,16,18,20]\n",
    "for trees in max_depth_options:\n",
    "    dtree = DecisionTreeClassifier(max_depth=trees, random_state=101, max_features = None, min_samples_leaf = 4)\n",
    "    scores = cross_val_score(dtree, X_train, y_train, cv=5)\n",
    "    results.append(scores.mean())\n",
    "plt.figure(figsize=(8,4))\n",
    "pd.Series(results, max_depth_options).plot(color=\"darkred\",marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> O melhor valor de profundidade máxima da árvore encontrado foi igual a 6</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=6, random_state=101, max_features = None, min_samples_leaf = 4)\n",
    "scores = cross_val_score(dtree, X_train, y_train, cv=5)\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Accuracy: %0.2f Desvio Padrão: (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Conclusões sobre as Descobertas </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "As etapas de análise e pré-processamento dos dados foram importantes para a realização deste trabalho pois através delas conseguimos descobrir padrões nos dados que estavam ocultos, além de prepará-los para o melhor desempenho dos algoritmos de classificação. Através de técnicas de pré-processamento, conseguimos contornar problemas de valores ausentes, converter valores nominais em tipos numéricos e padronizar valores em escalas de pesos.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Ao analisar os resultados dos modelos preditivos de classificação <i>k-Nearest Neighbours</i> (<i>k</i>-NN) e <i>Decision Tree</i> (Árvore de Decisão), podemos notar que os dois algoritmos de predição obtiveram diferentes resultados nas suas medidas de desempenho, sendo o algoritmo por árvore de decisão que obteve melhor desempenho. Além disso, a escolha dos métodos para particionar os conjuntos em treinamento e teste, influenciaram diretamente nos resultados dos algoritmos.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Através dos modelos preditivos de classificação gerados neste trabalho e com posse de dados desconhecidos que contenham os mesmos atributos relacionados a fatores de imunização, mortalidade, sociais e econômicos, conseguimos prever se um determinado registro será classificado como expectativa de vida: <font color=\"blue\">muito baixa</font>, <font color=\"blue\">baixa</font>, <font color=\"blue\">média</font> e <font color=\"blue\">alta</font>. Essa descoberta de conhecimento é de grande importância para que organizações mundiais de saúde e governamentais consigam identificar fatores que influenciem na expectativa de vida.    \n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook-intro.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
